"use strict";(()=>{var e={};e.id=932,e.ids=[932,888],e.modules={6962:(e,t,i)=>{i.a(e,async(e,r)=>{try{i.r(t),i.d(t,{config:()=>x,default:()=>h,getServerSideProps:()=>u,getStaticPaths:()=>p,getStaticProps:()=>m,reportWebVitals:()=>g,routeModule:()=>P,unstable_getServerProps:()=>b,unstable_getServerSideProps:()=>y,unstable_getStaticParams:()=>j,unstable_getStaticPaths:()=>_,unstable_getStaticProps:()=>f});var a=i(7093),s=i(5244),n=i(1323),o=i(4003),l=i(9597),c=i(8233),d=e([o,l,c]);[o,l,c]=d.then?(await d)():d;let h=(0,n.l)(c,"default"),m=(0,n.l)(c,"getStaticProps"),p=(0,n.l)(c,"getStaticPaths"),u=(0,n.l)(c,"getServerSideProps"),x=(0,n.l)(c,"config"),g=(0,n.l)(c,"reportWebVitals"),f=(0,n.l)(c,"unstable_getStaticProps"),_=(0,n.l)(c,"unstable_getStaticPaths"),j=(0,n.l)(c,"unstable_getStaticParams"),b=(0,n.l)(c,"unstable_getServerProps"),y=(0,n.l)(c,"unstable_getServerSideProps"),P=new a.PagesRouteModule({definition:{kind:s.x.PAGES,page:"/works/bioinformatics",pathname:"/works/bioinformatics",bundlePath:"",filename:""},components:{App:l.default,Document:o.default},userland:c});r()}catch(e){r(e)}})},7669:(e,t,i)=>{i.a(e,async(e,r)=>{try{i.d(t,{Z:()=>__WEBPACK_DEFAULT_EXPORT__});var a=i(997),s=i(6197),n=i(2210),o=e([s,n]);[s,n]=o.then?(await o)():o;let l=(0,n.chakra)(s.motion.div,{shouldForwardProp:e=>(0,n.shouldForwardProp)(e)||"transition"===e}),__WEBPACK_DEFAULT_EXPORT__=({children:e,delay:t=0})=>a.jsx(l,{initial:{y:10,opacity:0},animate:{y:0,opacity:1},transition:{duration:.8,delay:t},mb:6,children:e});r()}catch(e){r(e)}})},8233:(e,t,i)=>{i.a(e,async(e,r)=>{try{i.r(t),i.d(t,{default:()=>__WEBPACK_DEFAULT_EXPORT__,getServerSideProps:()=>m.N});var a=i(997),s=i(2210),n=i(6134),o=i(8849),l=i(1227),c=i(307),d=i(3915),h=i(7669),m=i(9142),p=e([s,n,o,l,c,d,h,m]);[s,n,o,l,c,d,h,m]=p.then?(await p)():p;let __WEBPACK_DEFAULT_EXPORT__=()=>a.jsx(c.Z,{title:"Bioinformatics",children:(0,a.jsxs)(s.Container,{children:[(0,a.jsxs)(o.Dx,{children:["Artificial Intelligence in Bioinformatics Project ",a.jsx(s.Badge,{children:"December 2024 - March 2025"})]}),a.jsx(h.Z,{children:a.jsx(s.Heading,{as:"h4",fontSize:16,my:6,children:a.jsx(s.Center,{children:"AI for Bioinformatics Project 2024/2025"})})}),a.jsx(h.Z,{delay:.1,children:a.jsx(l.Z,{children:"The visual examination of histopathological images is a cornerstone of cancer diagnosis, requiring pathologists to analyze tissue sections across multiple magnifications to identify tumor cells and subtypes. However, existing attention-based Multiple Instance Learning (MIL) models for Whole Slide Image (WSI) analysis often neglect contextual and numerical features, resulting in limited interpretability and potential misclassifications. Furthermore, the original MIL formulation incorrectly assumes the patches of the same image to be independent, leading to a loss of spatial context as information flows through the network. Incorporating contextual knowledge into predictions is particularly important given the inclination for cancerous cells to form clusters and the presence of spatial indicators for tumors. To address these limitations, we propose an enhanced MIL framework that integrates pre-contextual numerical information derived from semantic segmentation. Specifically, our approach combines visual features with nuclei-level numerical attributes, such as cell density and morphological diversity, extracted using advanced segmentation tools like Cellpose. These enriched features are then fed into a modified BufferMIL model for WSI classification. We evaluate our method on detecting lymph node metastases (CAMELYON16 and TCGA lung)."})}),(0,a.jsxs)(h.Z,{delay:.2,children:[a.jsx(s.Heading,{as:"h3",fontSize:20,my:6,children:"Repository"}),a.jsx(s.List,{ml:4,my:4,children:(0,a.jsxs)(s.ListItem,{children:[a.jsx(o.h_,{children:"GitHub"}),(0,a.jsxs)(s.Link,{href:"https://github.com/andrea-grandi/bio_project",target:"_blank",children:["AI for Bioinformatics Project ",a.jsx(n.ExternalLinkIcon,{mx:"2px"})]})]})}),a.jsx(s.Heading,{as:"h3",fontSize:20,my:6,children:"Credits"}),(0,a.jsxs)(s.List,{ml:4,my:4,children:[(0,a.jsxs)(s.ListItem,{children:[a.jsx(o.h_,{children:"Andrea Grandi"}),(0,a.jsxs)(s.Link,{href:"https://github.com/andrea-grandi",target:"_blank",children:["@andrea-grandi ",a.jsx(n.ExternalLinkIcon,{mx:"2px"})]})]}),(0,a.jsxs)(s.ListItem,{children:[a.jsx(o.h_,{children:"Daniele Vellani"}),(0,a.jsxs)(s.Link,{href:"https://github.com/franzione1",target:"_blank",children:["@franzione1 ",a.jsx(n.ExternalLinkIcon,{mx:"2px"})]})]})]})]})]})});r()}catch(e){r(e)}})},2785:e=>{e.exports=require("next/dist/compiled/next-server/pages.runtime.prod.js")},968:e=>{e.exports=require("next/head")},6689:e=>{e.exports=require("react")},6405:e=>{e.exports=require("react-dom")},997:e=>{e.exports=require("react/jsx-runtime")},9816:e=>{e.exports=require("styled-jsx/style")},6134:e=>{e.exports=import("@chakra-ui/icons")},2210:e=>{e.exports=import("@chakra-ui/react")},149:e=>{e.exports=import("@chakra-ui/theme-tools")},3139:e=>{e.exports=import("@emotion/react")},4115:e=>{e.exports=import("@emotion/styled")},9752:e=>{e.exports=import("@vercel/analytics/react")},6197:e=>{e.exports=import("framer-motion")},1017:e=>{e.exports=require("path")}};var t=require("../../webpack-runtime.js");t.C(e);var __webpack_exec__=e=>t(t.s=e),i=t.X(0,[801,142,859,450,201,675,829,597,562,226,915],()=>__webpack_exec__(6962));module.exports=i})();